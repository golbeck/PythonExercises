#First you need the train data and test data, we use the treebank data from nltk.corpus:
from nltk.corpus import treebank
len(treebank.tagged_sents())

train_data = treebank.tagged_sents()[:3000]
test_data = treebank.tagged_sents()[3000:]
train_data[0]

#We use the first 3000 treebank tagged sentences as the train_data, and last 914 tagged sentences as the test_data, now we train TnT POS Tagger by the train_data and evaluate it by the test_data:
from nltk.tag import tnt
tnt_pos_tagger = tnt.TnT()
tnt_pos_tagger.train(train_data)
tnt_pos_tagger.evaluate(test_data)

#You can save this pos tagger model as a pickle file:

import pickle
f = open('cpos_tagger.pickle', 'w')
pickle.dump(cpos_tagger, f)
f.close()

#And you can use it any time you want:

tnt_pos_tagger.tag(nltk.word_tokenize('this is a tnt treebank tnt tagger'))

##############################################################################################
##############################################################################################
##############################################################################################
#adapted from http://streamhacker.com/2010/04/12/pos-tag-nltk-brill-classifier/
import itertools
from nltk.corpus import brown, conll2000, treebank
 
brown_reviews = brown.tagged_sents(categories=['reviews'])
brown_reviews_cutoff = len(brown_reviews) * 2 / 3
brown_lore = brown.tagged_sents(categories=['lore'])
brown_lore_cutoff = len(brown_lore) * 2 / 3
brown_romance = brown.tagged_sents(categories=['romance'])
brown_romance_cutoff = len(brown_romance) * 2 / 3
 
brown_train = list(itertools.chain(brown_reviews[:brown_reviews_cutoff],
    brown_lore[:brown_lore_cutoff], brown_romance[:brown_romance_cutoff]))
brown_test = list(itertools.chain(brown_reviews[brown_reviews_cutoff:],
    brown_lore[brown_lore_cutoff:], brown_romance[brown_romance_cutoff:]))
 
conll_train = conll2000.tagged_sents('train.txt')
conll_test = conll2000.tagged_sents('test.txt')
 
treebank_cutoff = len(treebank.tagged_sents()) * 2 / 3
treebank_train = treebank.tagged_sents()[:treebank_cutoff]
treebank_test = treebank.tagged_sents()[treebank_cutoff:]

#train on treebank
cpos = nltk.tag.sequential.ClassifierBasedPOSTagger(train=treebank.tagged_sents())
cpos.evaluate(treebank_test)
cpos.tag(nltk.word_tokenize('the little yellow dog barked at the cat'))
#train on brown
cpos = nltk.tag.sequential.ClassifierBasedPOSTagger(train=brown_train)
cpos.evaluate(brown_test)
cpos.tag(nltk.word_tokenize('the little yellow dog barked at the cat'))
#Brown POS tags: http://www.scs.leeds.ac.uk/ccalas/tagsets/brown.html
import pickle
f = open('cpos_tagger.pickle', 'w')
pickle.dump(cpos, f)
f.close()

